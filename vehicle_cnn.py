# -*- coding: utf-8 -*-
"""vehicle_cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DYOL-8stQv-yfiLL-lzrbaENJd3kIKt1
"""

import os
import tensorflow as tf
from keras.preprocessing.image import load_img, img_to_array
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D
from keras.models import Model,Sequential
from tensorflow.keras.optimizers import Adam,SGD,RMSprop

from google.colab import drive
drive.mount('/content/drive')

import matplotlib.pyplot as plt
import numpy as np

picture_size = 256
folder_path = "/content/drive/MyDrive/Colab Notebooks/datasets/vehicle_detection/"
LABEL = ['Scooter', 'Truck', 'Bus', 'Autorickshaw', 'Bicycle', 'Cars', 'Bike', 'Rickshaw']

data = 'train' + "/" # test or train
label = LABEL[3] + "/"
image_paths = os.listdir(folder_path + data + label)

plt.figure(figsize= (12,12))
for i in range(1, 10, 1):
    plt.subplot(3,3,i)
    # img = load_img(folder_path+ data + label + 
    #               image_paths[np.random.randint(0,len(image_paths))], target_size=(picture_size, picture_size))
    # plt.imshow(img)  
    # print(np.array(img).shape) 
plt.show()

batch_size  = 64

datagen_train  = ImageDataGenerator(rescale = 1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2)
datagen_val = ImageDataGenerator()

train_set = datagen_train.flow_from_directory(folder_path+"train",
                                              target_size = (picture_size,picture_size),
                                              # color_mode = "grayscale",
                                              batch_size=batch_size,
                                              class_mode='categorical',
                                              shuffle=True)


test_set = datagen_val.flow_from_directory(folder_path+"test",
                                              target_size = (picture_size,picture_size),
                                              # color_mode = "grayscale",
                                              # batch_size=batch_size,
                                              class_mode='categorical',
                                              shuffle=False)

model = tf.keras.applications.VGG16(include_top=False, input_tensor=tf.keras.layers.Input(shape=(256, 256, 3)))

model.summary()

base_input = model.layers[0].input
base_output = model.layers[-1].output

base_output = tf.keras.layers.Flatten(name="flatten")(base_output)
# custom_layer = tf.keras.layers.Dense(4096, activation="relu")(base_output)
# custom_layer = tf.keras.layers.Dense(2048, activation="relu")(custom_layer)
custom_layer = tf.keras.layers.Dense(128, activation="relu")(base_output)
custom_layer = tf.keras.layers.Dense(64, activation="relu")(custom_layer)
final_output = tf.keras.layers.Dense(8, activation="softmax", name="output")(custom_layer)

custom_model = tf.keras.Model(inputs = base_input, outputs = final_output)

custom_model.summary()

custom_model.compile(optimizer=SGD(),loss='categorical_crossentropy', metrics=['accuracy'])

custom_model.fit(train_set, epochs = 1, steps_per_epoch=(train_set.n//train_set.batch_size))

